{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 处理文件夹: D:\\Dataset\\Data_Watkins\\Best_WhiteBeaked_sounds (WhiteBeaked)\n",
      "\n",
      "📂 处理文件夹: D:\\Dataset\\Data_Watkins\\Best_AtlanticSpotted_sounds (AtlanticSpotted)\n",
      "\n",
      "📂 处理文件夹: D:\\Dataset\\Data_Watkins\\Best_WhiteSided_sounds (WhiteSided)\n",
      "\n",
      "📊 数据统计结果：\n",
      "\n",
      "🔹 WhiteBeaked:\n",
      "   LHR > 1: 49  |  LHR < 1: 8\n",
      "   SNR 0-10: 10  |  SNR 10-20: 34\n",
      "   SNR 20-30: 13  |  SNR 30+: 0\n",
      "\n",
      "🔹 AtlanticSpotted:\n",
      "   LHR > 1: 16  |  LHR < 1: 42\n",
      "   SNR 0-10: 33  |  SNR 10-20: 23\n",
      "   SNR 20-30: 2  |  SNR 30+: 0\n",
      "\n",
      "🔹 WhiteSided:\n",
      "   LHR > 1: 36  |  LHR < 1: 19\n",
      "   SNR 0-10: 24  |  SNR 10-20: 30\n",
      "   SNR 20-30: 1  |  SNR 30+: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# 定义文件夹路径\n",
    "folders = {\n",
    "    \"WhiteBeaked\": r\"D:\\Dataset\\Data_Watkins\\Best_WhiteBeaked_sounds\",\n",
    "    \"AtlanticSpotted\": r\"D:\\Dataset\\Data_Watkins\\Best_AtlanticSpotted_sounds\",\n",
    "    \"WhiteSided\": r\"D:\\Dataset\\Data_Watkins\\Best_WhiteSided_sounds\"\n",
    "}\n",
    "\n",
    "def compute_snr_lhr_adaptive(signal, sample_rate):\n",
    "    \"\"\"\n",
    "    计算 SNR（信噪比）和 LHR（低频/高频比）\n",
    "    \"\"\"\n",
    "    # 计算傅里叶变换\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    psd_signal = np.abs(fft_signal) ** 2  # 计算功率谱密度\n",
    "    freqs = np.fft.fftfreq(len(signal), d=1/sample_rate)\n",
    "    freqs = freqs[:len(freqs) // 2]\n",
    "    psd_signal = psd_signal[:len(psd_signal) // 2]\n",
    "\n",
    "    # --- 计算能量中心 ---\n",
    "    spectral_centroid = np.sum(freqs * psd_signal) / (np.sum(psd_signal) + 1e-8)\n",
    "\n",
    "    # --- 计算 SNR ---\n",
    "    geometric_mean = np.exp(np.mean(np.log(psd_signal + 1e-8)))  # 避免 log(0)\n",
    "    arithmetic_mean = np.mean(psd_signal)\n",
    "    sfm = geometric_mean / (arithmetic_mean + 1e-8)\n",
    "    threshold = np.percentile(psd_signal, 90 * (1 - sfm))\n",
    "    signal_power = np.sum(psd_signal[psd_signal > threshold])\n",
    "    noise_power = np.sum(psd_signal[psd_signal <= threshold])\n",
    "    snr = 10 * np.log10(signal_power / (noise_power + 1e-8))\n",
    "\n",
    "    # --- 计算 LHR ---\n",
    "    low_freq_power = np.sum(psd_signal[freqs < spectral_centroid])\n",
    "    high_freq_power = np.sum(psd_signal[freqs >= spectral_centroid])\n",
    "    lhr = low_freq_power / (high_freq_power + 1e-8)\n",
    "\n",
    "    return snr, lhr\n",
    "\n",
    "# 遍历每个文件夹\n",
    "stats = {}\n",
    "\n",
    "for label, folder in folders.items():\n",
    "    print(f\"\\n📂 处理文件夹: {folder} ({label})\")\n",
    "\n",
    "    # 初始化统计计数\n",
    "    lhr_gt_1 = 0  # LHR > 1 的数量\n",
    "    lhr_lt_1 = 0  # LHR < 1 的数量\n",
    "    snr_bins = { \"0-10\": 0, \"10-20\": 0, \"20-30\": 0, \"30+\": 0 }  # SNR 分布\n",
    "\n",
    "    # 遍历文件夹中的音频文件\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".wav\"):  # 只处理 WAV 文件\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            # 读取音频文件\n",
    "            signal, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # 计算 SNR 和 LHR\n",
    "            snr, lhr = compute_snr_lhr_adaptive(signal, sr)\n",
    "\n",
    "            # 更新 LHR 计数\n",
    "            if lhr > 1:\n",
    "                lhr_gt_1 += 1\n",
    "            else:\n",
    "                lhr_lt_1 += 1\n",
    "\n",
    "            # 更新 SNR 计数\n",
    "            if 0 <= snr < 10:\n",
    "                snr_bins[\"0-10\"] += 1\n",
    "            elif 10 <= snr < 20:\n",
    "                snr_bins[\"10-20\"] += 1\n",
    "            elif 20 <= snr < 30:\n",
    "                snr_bins[\"20-30\"] += 1\n",
    "            else:\n",
    "                snr_bins[\"30+\"] += 1\n",
    "\n",
    "    # 存储统计结果\n",
    "    stats[label] = {\n",
    "        \"LHR > 1\": lhr_gt_1,\n",
    "        \"LHR < 1\": lhr_lt_1,\n",
    "        \"SNR 分布\": snr_bins\n",
    "    }\n",
    "\n",
    "# 打印统计结果\n",
    "print(\"\\n📊 数据统计结果：\")\n",
    "for label, data in stats.items():\n",
    "    print(f\"\\n🔹 {label}:\")\n",
    "    print(f\"   LHR > 1: {data['LHR > 1']}  |  LHR < 1: {data['LHR < 1']}\")\n",
    "    print(f\"   SNR 0-10: {data['SNR 分布']['0-10']}  |  SNR 10-20: {data['SNR 分布']['10-20']}\")\n",
    "    print(f\"   SNR 20-30: {data['SNR 分布']['20-30']}  |  SNR 30+: {data['SNR 分布']['30+']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# 定义文件夹路径\n",
    "folder_1 = r\"D:\\Dataset\\Data_Watkins\\Best_WhiteBeaked_sounds\"\n",
    "folder_2 = r\"D:\\Dataset\\Data_Watkins\\Best_AtlanticSpotted_sounds\"\n",
    "folder_3 = r\"D:\\Dataset\\Data_Watkins\\Best_WhiteSided_sounds\"\n",
    "\n",
    "# 目标采样点数\n",
    "target_length = 50000\n",
    "\n",
    "# 处理音频文件的函数\n",
    "def process_audio_files(folder):\n",
    "    processed_audios = []\n",
    "    audio_ids = []  # 存储文件 ID\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "\n",
    "            # 读取音频\n",
    "            audio, sr = librosa.load(file_path, sr=None)  # 保持原始采样率\n",
    "            total_samples = len(audio)\n",
    "\n",
    "            # 记录文件 ID（不包含扩展名）\n",
    "            file_id = os.path.splitext(file)[0]\n",
    "\n",
    "            # 如果音频长度不足 target_length，则前面补零\n",
    "            if total_samples < target_length:\n",
    "                audio = np.pad(audio, (target_length - total_samples, 0), mode='constant')\n",
    "                processed_audios.append(audio)\n",
    "                audio_ids.append(file_id)  # 记录 ID\n",
    "            else:\n",
    "                # 计算应切分的段数\n",
    "                num_segments = max(1, round(total_samples / target_length))\n",
    "                segment_length = total_samples // num_segments\n",
    "\n",
    "                for i in range(num_segments):\n",
    "                    start = i * segment_length\n",
    "                    end = min(start + target_length, total_samples)  # 确保不越界\n",
    "\n",
    "                    segment = audio[start:end]  # 默认切片\n",
    "                    if len(segment) < target_length:\n",
    "                        segment = np.pad(segment, (0, target_length - len(segment)), mode='constant')  # 不足时填充0\n",
    "\n",
    "                    processed_audios.append(segment)\n",
    "                    audio_ids.append(f\"{file_id}_seg{i}\")  # 记录分割后的 ID\n",
    "\n",
    "    return np.array(processed_audios), np.array(audio_ids)\n",
    "\n",
    "# 处理三个文件夹\n",
    "data_whitebeaked, ids_whitebeaked = process_audio_files(folder_1)\n",
    "data_atlanticspotted, ids_atlanticspotted = process_audio_files(folder_2)\n",
    "data_whitesided, ids_whitesided = process_audio_files(folder_3)\n",
    "\n",
    "# 对每个样本归一化到 [-1, 1]\n",
    "def normalize_audio(data):\n",
    "    return np.array([sample / np.max(np.abs(sample)) if np.max(np.abs(sample)) > 0 else sample for sample in data])\n",
    "\n",
    "data_whitebeaked = normalize_audio(data_whitebeaked)\n",
    "data_atlanticspotted = normalize_audio(data_atlanticspotted)\n",
    "data_whitesided = normalize_audio(data_whitesided)\n",
    "\n",
    "# 保存音频数据\n",
    "np.save(\"whitebeaked_sounds.npy\", data_whitebeaked)\n",
    "np.save(\"atlanticspotted_sounds.npy\", data_atlanticspotted)\n",
    "np.save(\"whitesided_sounds.npy\", data_whitesided)\n",
    "\n",
    "# 保存音频 ID（可选择保存为 .npy 或 .txt）\n",
    "np.save(\"whitebeaked_ids.npy\", ids_whitebeaked)\n",
    "np.save(\"atlanticspotted_ids.npy\", ids_atlanticspotted)\n",
    "np.save(\"whitesided_ids.npy\", ids_whitesided)\n",
    "\n",
    "# 也可以保存为可读的 .txt 文件\n",
    "np.savetxt(\"whitebeaked_ids.txt\", ids_whitebeaked, fmt=\"%s\")\n",
    "np.savetxt(\"atlanticspotted_ids.txt\", ids_atlanticspotted, fmt=\"%s\")\n",
    "np.savetxt(\"whitesided_ids.txt\", ids_whitesided, fmt=\"%s\")\n",
    "\n",
    "# 输出数组大小\n",
    "print(f\"WhiteBeaked sounds shape: {data_whitebeaked.shape}, IDs: {ids_whitebeaked.shape}\")\n",
    "print(f\"AtlanticSpotted sounds shape: {data_atlanticspotted.shape}, IDs: {ids_atlanticspotted.shape}\")\n",
    "print(f\"WhiteSided sounds shape: {data_whitesided.shape}, IDs: {ids_whitesided.shape}\")\n",
    "\n",
    "print(\"处理完成，数据及音频 ID 已保存。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TarRec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
